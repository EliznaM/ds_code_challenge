---
title: "Untitled"
output: html_document
date: "2023-08-11"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.height = 16, fig.width = 20)
```

## Overview

Describe brief, outline of document. 

```{r setup2}

# libraries
library(kableExtra)
library(knitr)
library(lubridate)
library(tidyverse)

# colours and theme
  # COCT colours



# functions


```

## Methods

Describe data prep, code generalisable, tech details - missingness, exclusion decisions, choice of vars (e.g. code var).

```{r data_prep, results='hide'}
# output from this code chunk should not print in report

# read file from local

dta <- read_csv("data/sr_hex_truncated.csv")

# data checks ----------------------------------------

glimpse(dta)

sum(is.na(dta$notification_number))
# no missing notification nrs

length(dta$notification_number) == length(unique(dta$notification_number))
# each row is unique entry


  # numeric cols ---------

summary(dta$latitude)
summary(dta$longitude)
  
  # date cols -----------

unique(lubridate::as_date(dta$creation_timestamp)) 
# none missing
# exlude 1 date in dec-2019
unique(lubridate::as_date(dta$completion_timestamp))
# some NAs, explore later

# create new variables -----------------------------------------

  # make month and year columns ------

dta <- dta %>% 
  mutate(year_creation = lubridate::year(creation_timestamp),
         month_creation = lubridate::month(creation_timestamp),
         year_completion = lubridate::year(completion_timestamp),
         month_completion = lubridate::month(completion_timestamp))

mnths <- c("jan", "feb", "mar", "apr", "may", "jun", "jul",
           "aug", "sep", "oct", "nov", "dec")

dta$month_creation <- factor(dta$month_creation, levels = 1:12,  labels = mnths)
dta$month_completion <- factor(dta$month_completion, levels = 1:12, labels = mnths)

  # make time-to-complete columns ------
  # note %--% is a lubridate-specific operator

dta <- dta %>% 
   mutate(interv = creation_timestamp %--% completion_timestamp,
          time_hours = as.duration(interv) / dhours(1),
          time_days = as.duration(interv) / ddays(1),
          time_weeks = as.duration(interv) / dweeks(1)) %>% 
  select(-interv)
  


```


#### Missingness

```{r missing1}

n_cutoff <- 5

tmp <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing), desc(n_missing)) %>% 
  ungroup()

# max(tmp$percentage_missing)
# tmp$official_suburb[tmp$percentage_missing == max(tmp$percentage_missing)]

tmp <- dta %>% 
  select(directorate, department, branch, section, official_suburb) %>% 
  mutate(across(everything(), ~as.numeric(is.na(.x)))) %>% 
  as.data.frame()
head(tmp)

mis_dir_nonmis_sub <- tmp %>% 
  group_by(directorate, official_suburb) %>% 
  count() %>% 
  filter(directorate == 1 & official_suburb == 0) %>% 
  pull(n)


```

Missingness of specific data entries can be meaningful, e.g. it can point to operational failures if a specific region has more missing data than another.  Therefore it is important to interrogate patterns of missingness in data. We investigated missingness that would make interpretation hard.  Entries for which any of the Directorate, Department, Branch, Section or Official suburb were missing are visualised (Figure A). Entries with missing Directorate were in general also missing for the other categories. Suburbs for which there were at least `r n_cutoff` entries, and for which Directorate was missing, but Official suburb was not(n = `r mis_dir_nonmis_sub`), accounted for at most `r tmp$percentage_missing` of entries for any suburb and the suburb with the highest percentage of missing entries of this kind, was `r tmp$official_suburb[tmp$percentage_missing == max(tmp$percentage_missing)]`(Figure B). 

```{r missing2}

na_interpret_affected <- UpSetR::upset(tmp)

na_interpret_affected
grid::grid.text("Fig. A",x = 0.65, y=0.95, gp=grid::gpar(fontsize=20))

plotdta <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  arrange(desc(n_missing), desc(percentage_missing)) %>% 
  ungroup() 

plotdta %>% 
  slice(1:20) %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(official_suburb, percentage_missing), size = n_missing))+
  labs(title = "Fig. B: Top 20 Suburbs with missing Directorate")

# missing directorate and dates

dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, is.na(directorate)) %>% 
               count(name = "n_missing")) %>%
  ungroup() %>% 
  rename(missing_directorate = 4) %>% 
  filter(missing_directorate == TRUE) %>% 
  mutate(percentage_missing = n_missing/total_ym*100) %>% 
  kable() %>%
  kable_styling(full_width = FALSE, position = "left")

```

Of the entries with Official suburb missing, ...

```{r}

plotdta <- dta %>% 
  group_by(directorate) %>% 
  count(name = "total_directorate") %>%
  inner_join(dta %>% 
               filter(is.na(official_suburb)) %>% 
               group_by(directorate) %>% 
                        count(name = "n_missing")) %>% 
  ungroup() %>% 
  mutate(percentage_missing = n_missing/total_directorate*100)

plotdta %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(directorate, percentage_missing), size = n_missing))+
  labs(title = "Fig. C: Missing Suburbs per Directorate")

# Exclude if missing directorate

dta <- dta %>% 
  filter(!is.na(directorate))


# Missingness in urban mobility
unique(dta$directorate)

dta_um <- dta %>% 
  filter(directorate == "URBAN MOBILITY")

x <- which(names(dta_um) %in% c("code_group", "code", "cause_code_group", "cause_code"))

map(dta_um[x], ~sort(unique(.x))) 
map(dta_um[x], ~sum(is.na(.x))) 

dta_um %>%
  select(all_of(x)) %>% 
  group_by(is.na(.)) %>% 
  count()

x <- nrow(dta_um)

x1 <- dta_um %>% 
  group_by(is.na(cause_code_group), is.na(cause_code)) %>% 
  count(name = "missing_cause") %>% 
  ungroup() %>% 
  rename(...1 = 1, ...2 = 2) %>% 
  filter(...1 == TRUE & ...2 == TRUE) %>% 
  pull(missing_cause)

tibble(msg = glue::glue("Missing cause for {round(x1/x*100, 2)}% of Urban Mobility entries.")) %>% 
  kable(col.names = NULL) %>%
  kable_styling(full_width = FALSE, position = "left")

```





```{r}

# prepare ----------------------------------------------------------

  # exclusions -------

# exclude creation date 2019, as only 31 Dec is represented

dta <- dta %>% 
  filter(creation_timestamp >= lubridate::as_datetime("2020-01-01 00:00:00 UTC"))


  
```


### Description of the data and preparation steps



```{r overview}
x <- nrow(dta)

dta %>% 
  group_by(directorate) %>% 
  count(name = "Nr_of_entries") %>% 
  mutate(Percentage_of_total = round(Nr_of_entries/x*100, 2)) %>% 
  arrange(desc(Nr_of_entries)) %>% 
  rename(Directorate = directorate) %>% 
  kable(title = "Number and percentage of entries per Directorate") %>%
  kable_styling(full_width = FALSE, position = "left")

dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, directorate) %>% 
               count(name = "Nr_of_entries")) %>% 
  ungroup() %>% 
  mutate(Percentage_of_total = round(Nr_of_entries/total_ym*100, 2)) %>% 
  arrange(desc(Nr_of_entries)) %>% 
  ggplot(aes(month_creation, Percentage_of_total, 
             fill = reorder(directorate, Percentage_of_total)))+
  geom_col()+
  facet_wrap(~year_creation, scales = "free_x") # resize left bar?



```



## "In which 3 suburbs should the Urban Mobility directorate concentrate their infrastructure improvement efforts?"

```{r}
# department, branch, section, code_group not helpful
dta_um %>% 
  group_by(code, cause_code) %>% 
  count() %>% 
  print(n = Inf)

# filter out cause codes "Not Defined" etc, but keep NA

dta_um <- dta_um %>% 
  filter(!cause_code %in% c("No Cause Found",
                           "None/Private") &
           !is.na(official_suburb))

dta_um %>% 
  group_by(official_suburb) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  print(n = 20)

# top 10 by month 

plotdta <- dta_um %>% 
  group_by(year_creation, month_creation, official_suburb) %>% 
  count() %>% 
  arrange(year_creation, month_creation, desc(n)) %>% 
  print(n = 20) %>% 
  ungroup()

plotdta <- map(unique(plotdta$month_creation),
           ~plotdta %>% 
  filter(month_creation == .x) %>% 
  arrange(desc(n)) %>% 
  slice(1:10)) %>% 
    bind_rows()

dta_um %>% 
  group_by(official_suburb) %>% 
  count(name = "total_overall") %>% 
  inner_join(plotdta) %>% 
  ggplot(aes(n, official_suburb, fill = total_overall))+
  geom_col()+
  facet_wrap(~month_creation)

# looks like parklands, milnerton, table view, marconi beam

# if look at median across months
dta_um %>% 
  group_by(month_creation, official_suburb) %>% 
  count() %>% 
  ungroup() %>% 
  group_by(official_suburb) %>% 
  summarise(med = median(n)) %>% 
  ungroup() %>% 
  arrange(desc(med))

x <- c("PARKLANDS", "MARCONI BEAM", "BRACKENFELL COMMON",
       "TABLE VIEW", "MILNERTON")

dta_um %>% 
  filter(official_suburb %in% x) %>% 
  group_by(official_suburb, code) %>% 
  count() %>% 
  ungroup() %>% 
  ggplot(aes(n, code, fill = official_suburb))+
  geom_col(position = "dodge")



```



## 1. Focusing on the Urban Mobility directorate - "What is the median & 80th percentile time to complete each service request across the City?" (each row represent a service request).

```{r}
# get back no fault found etc.

dta_um <- dta %>% 
  filter(directorate == "URBAN MOBILITY")

# completion time missing
x <- nrow(dta_um)

dta_um %>% 
  group_by(is.na(completion_timestamp)) %>% 
  count(name = "Nr") %>% 
  ungroup() %>% 
  rename(Missing_completion_time = 1) %>% 
  mutate(across(Missing_completion_time, ~ifelse(.x == TRUE, "yes", "no")),
         Percentage = round(Nr/x*100, 2)) %>% 
  kable() %>%
  kable_styling(full_width = FALSE, position = "left")

# breakdown of entries with missing completion times

x <- c("department", "branch", "section", "code_group",
  "code", "cause_code_group", "cause_code", "official_suburb")

tmp <- map(x, 
    ~dta_um %>% 
  filter(is.na(completion_timestamp)) %>% 
  select(notification_number, all_of(.x)) %>% 
  mutate(across(-notification_number, ~paste(cur_column(), .x, sep = ":")),
         value = 1) %>% 
    rename(key = 2) %>% 
  pivot_wider(names_from = key, values_from = value)) %>% 
  purrr::reduce(inner_join) %>% 
  as.data.frame()

tmp[is.na(tmp)] <- 0

UpSetR::upset(tmp)

# exclude data with no completion time, create diff var

dta_um <- dta_um %>% 
  filter(!is.na(completion_timestamp)) %>% 
   mutate(time_hrs = as.integer(completion_timestamp - creation_timestamp)/60)

```


```{r}
#  create table withs medians, q80 for all suburbs and for all of city 

time_tables_make <- function(dataset = dta_um, time_cutoff = NULL){
  
  sub_txt <- "ALL COMBINED"
  code_txt <- "All codes combined"
  
  if(is.null(time_cutoff)){
  
  tabledta <- dataset %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
                 mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
    ungroup())

  return(tabledta)
  
} else if(!is.null(time_cutoff)){
  
  dataset_x <- dataset %>% 
    filter(time_hrs < time_cutoff)
  
  tabledta_below <- dataset_x %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset_x %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
              mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
    ungroup())
  
  dataset_x <- dataset %>% 
    filter(time_hrs >= time_cutoff)
  
  tabledta_above <- dataset_x %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset_x %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
              mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb, code) %>% 
  summarise(med_time_hrs = median(time_hrs),
            q80_time_hrs = quantile(time_hrs, probs = 0.8)) %>% 
    ungroup())
  
  return(list(tabledta_below = tabledta_below,
                tabledta_above = tabledta_above))
}
}

time_dta_list <- list()

# for all of city, all codes, all completion time lengths

time_dta_list$all_times <- time_tables_make(dataset = dta_um, time_cutoff = NULL)

# for all of city, all codes, split by times < or > 96hrs
tmp <- time_tables_make(dataset = dta_um, time_cutoff = 96)

time_dta_list$below_96 <- tmp$tabledta_below 
time_dta_list$above_eq_96 <- tmp$tabledta_above 

# look at suburbs with n >= 5
# all codes combined

n_cutoff <- 5
sub_txt <- "ALL COMBINED"
code_txt <- "All codes combined"

time_dta_list$all_times %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(caption = "City-wide, all codes combined") %>%
  kable_styling(full_width = FALSE, position = "left")
  
time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  arrange(desc(med_time_hrs)) %>% 
  slice(1:5) %>% 
  kable(caption = "Top 5 suburbs with long median completion times, all codes combined") %>%
  kable_styling(full_width = FALSE, position = "left")

time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  arrange(med_time_hrs) %>% 
  slice(1:5) %>% 
  kable(caption = "Top 5 suburbs with short median completion times, all codes combined") %>%
  kable_styling(full_width = FALSE, position = "left")


# split by codes
# codes with > 5 requests, per suburb
# show top 5 per code

n_cutoff <- 5
sub_txt <- "ALL COMBINED"
code_txt <- "All codes combined"

tmp <- time_dta_list$all_times %>% 
  filter(official_suburb == sub_txt &
           code != code_txt &
           n >= n_cutoff) %>% 
  arrange(desc(med_time_hrs)) 

code_txt <- tmp$code[2]

plotdta <- tmp %>% 
  mutate(set = "City-wide") %>% 
  filter(code == code_txt) %>% 
  bind_rows(time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n != 1) %>% 
  arrange(desc(med_time_hrs)) %>% 
  slice(1:5) %>% 
    mutate(set = "top_long_times")) %>% 
  bind_rows(time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt,
         n != 1) %>% 
  arrange(med_time_hrs) %>% 
  slice(1:5) %>% 
    mutate(set = "top_short_times")) %>% 
  pivot_longer(cols = c(med_time_hrs, q80_time_hrs),
               names_to = "quantile", values_to = "time_hrs")

x <- plotdta %>% 
  filter(quantile == "med_time_hrs") %>% 
  select(official_suburb, time_hrs) %>% 
  arrange(desc(time_hrs)) %>% 
  pull(official_suburb)

plotdta$official_suburb <- factor(plotdta$official_suburb,
                                  levels = unique(x))

plotdta %>% 
  ggplot(aes(time_hrs, official_suburb, colour = set))+
  geom_point()


# per month




# weekends, public holidays?

```



```{r}

plotdta <- dta_um %>% 
  mutate(diff_time_hrs = as.integer(completion_timestamp - creation_timestamp)/60) %>% 
  select(notification_number, diff_time_hrs, code_group, code, cause_code_group,
         cause_code, official_suburb)


plot_time_per_var <- function(dataset = plotdta, column = "code_group", hours_cutoff = 96){
  
  x <- which(names(dataset) == column)
  dataset <- dataset %>% 
    rename(col_select = x) 
  
  tmp <- dataset %>% 
  group_by(col_select) %>% 
  summarise(n = n(),
            med_hrs = median(diff_time_hrs),
            q5 = quantile(diff_time_hrs, probs = 0.05),
            q80 = quantile(diff_time_hrs, probs = 0.8),
            q95 = quantile(diff_time_hrs, probs = 0.95)) %>% 
  ungroup() 
  
  dataset %>% 
    mutate(col_select = "all_combined") %>% 
    group_by(col_select) %>% 
  summarise(n = n(),
            med_hrs = median(diff_time_hrs),
            q5 = quantile(diff_time_hrs, probs = 0.05),
            q80 = quantile(diff_time_hrs, probs = 0.8),
            q95 = quantile(diff_time_hrs, probs = 0.95)) %>% 
  ungroup() 
  
  

p1 <- tmp %>% 
  filter(q95 < hours_cutoff) %>% 
  select(col_select) %>% 
  inner_join(dataset %>% 
               select(col_select, diff_time_hrs)) %>% 
  ggplot(aes(diff_time_hrs, col_select))+
  ggdist::stat_interval()+
  labs(y = column)

p2 <- tmp %>% 
  filter(q5 >= hours_cutoff) %>% 
  select(col_select) %>% 
  inner_join(dataset) %>% 
  mutate(time_weeks = (diff_time_hrs/24)/7) %>% 
  ggplot(aes(time_weeks, col_select))+
  ggdist::stat_interval()+
  labs(y = column)

return(list(hours = p1, weeks = p2))

}

plotlist <- plot_time_per_var(dataset = plotdta, column = "code_group", hours_cutoff = 96)

ggpubr::ggarrange(plotlist = plotlist)


plotlist <- plot_time_per_var(dataset = plotdta, column = "code", hours_cutoff = 96)

ggpubr::ggarrange(plotlist = plotlist)


plotlist <- plot_time_per_var(dataset = plotdta, column = "cause_code_group", hours_cutoff = 96)

ggpubr::ggarrange(plotlist = plotlist)


plotlist <- plot_time_per_var(dataset = plotdta, column = "cause_code", hours_cutoff = 96)

ggpubr::ggarrange(plotlist = plotlist)

plotdta %>% 
  ggplot(aes(diff_time_hrs, official_suburb))+
  ggdist::stat_interval()


ggpubr::ggarrange(plotlist = plotlist)


```





    
## 2. Focusing on the Urban Mobility directorate - "What is the median & 80th percentile time to complete each service request for the 3 suburbs identified in (1)?" (each row represent a service request).



## 3. "Is there any significant differences in the median and 80th percentile completion times between the City as a whole and the 3 suburbs identified in(1)?".  Please elaborate on the similarities or differences.


## 3. Provide a visual mock of a dashboard for the purpose of monitoring progress in applying the insights developed in (1) & (2). It should focus the user on performance pain points. Add a note for each visual element, explaining how it helps fulfill this overall function. Please also provide a brief explanation as to how the data provided would be used to realise what is contained in your mock.


## 4. Identify value-adding insights for the management of Urban Mobility, from the dataset provided, in regard to commuter transport within the City.
 