---
title: "COCT Urban Mobility"
output: pdf_document
author:  "E Maasdorp"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[width=2in,height=2in]{img/city_emblem.png}\LARGE\\}
  - \posttitle{\end{center}}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.height = 16, fig.width = 20)
```

## Overview

**Note from the author:  This report was compiled to complete the City of Cape Town (COCT) data science challenge.  It is not an official COCT report.**  
The goal of this analysis is to highlight COCT suburbs that the Urban Mobility Directorate should focus on, for infrastructure improvements, based on service request data for 4 months (December 2019 to March 2020). It also explored intervals between creation and completion of service requests, to assess performance across the city. In future, the identification of performance pain points can be aided by a performance tracking dashboard, for which a visual mock-up is provided.  Finally, some insights relevant to commuter transport, gained from the current data, are provided.    

```{r setup2}

# libraries
library(kableExtra)
library(knitr)
library(lubridate)
library(tidyverse)

# colours and theme
  # COCT colours

coct_cols <- c("#C7006E", "#B9CF00","#00A6CD", "#FF9900",  "#000000")

theme_set(theme_light())

# functions


# parameters

select_directorate <- "URBAN MOBILITY"
# specify the Directorate this analysis focuses on

```

## Methods

The ```sr_hex_truncated.csv``` dataset was provided for this analysis. It originates from service requests across COCT spanning December 2019 to March 2020.  The analysis was performed in the Statistical Programming Language R, using a RMarkdown file to produce this document.  The code is available in a Github repository () and this analysis should be fully reproducible.  The R and package versions used are listed at the end of this document in an appendix.  
The dataset was explored and new variables created from existing ones, as necessary. Tables and plots were used to communicate useful summaries. Medians, quantiles and non-parametric tests for differences in service request completion times were used because of skew data distribution. 
Only 1 day of 2019 is represented in the data (31 December) and it was excluded from the analysis.  Missing data entries were explored and details focusing on missingness can be found in the appendix at the end of this document.    Service request data that are hard to interpret because of missing entries in specific variables, were excluded:  rows with missing Directorate for all analyses, rows with missing Official Suburb, for analyses specifically comparing suburbs, and rows with missing service request completion dates for completion time analyses.
The data contains 4 service request code variables that provide descriptions of the type of request.  Due to severe missingness in two of these, and the differences in granularity in the remaining two, only the ```code``` variable was used to compare and provide insight into the types and frequency of requests.  

```{r data_check, results='hide'}
# output from this code chunk should not print in report

# read file from local

dta <- read_csv("data/sr_hex_truncated.csv")

# data checks ----------------------------------------

glimpse(dta)

sum(is.na(dta$notification_number))
# no missing notification nrs

length(dta$notification_number) == length(unique(dta$notification_number))
# each row is unique entry


  # numeric cols ---------

summary(dta$latitude)
summary(dta$longitude)
  
  # date cols -----------

unique(lubridate::as_date(dta$creation_timestamp)) 
# none missing
# exlude 1 date in dec-2019
unique(lubridate::as_date(dta$completion_timestamp))
# some NAs, explore later

# create new variables -----------------------------------------

  # make month and year columns ------

dta <- dta %>% 
  mutate(year_creation = lubridate::year(creation_timestamp),
         month_creation = lubridate::month(creation_timestamp),
         year_completion = lubridate::year(completion_timestamp),
         month_completion = lubridate::month(completion_timestamp))

mnths <- c("jan", "feb", "mar", "apr", "may", "jun", "jul",
           "aug", "sep", "oct", "nov", "dec")

dta$month_creation <- factor(dta$month_creation, levels = 1:12,  labels = mnths)
dta$month_completion <- factor(dta$month_completion, levels = 1:12, labels = mnths)

  # make time-to-complete columns ------
  # note %--% is a lubridate-specific operator

dta <- dta %>% 
   mutate(interv = creation_timestamp %--% completion_timestamp,
          time_hours = as.duration(interv) / dhours(1),
          time_days = as.duration(interv) / ddays(1),
          time_weeks = as.duration(interv) / dweeks(1)) %>% 
  select(-interv)
  
```


```{r missing1}

#### Missingness - include these results in appendix
# save in appendix list
appx_list <- list()

n_cutoff <- 5

appx_list$miss_dir <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing), desc(n_missing)) %>% 
  ungroup()

# max(tmp$percentage_missing)
# tmp$official_suburb[tmp$percentage_missing == max(tmp$percentage_missing)]

appx_list$upset_data <- dta %>% 
  select(directorate, department, branch, section, official_suburb) %>% 
  mutate(across(everything(), ~as.numeric(is.na(.x)))) %>% 
  as.data.frame()


appx_list$mis_dir_nonmis_sub <- appx_list$upset_data %>% 
  group_by(directorate, official_suburb) %>% 
  count() %>% 
  filter(directorate == 1 & official_suburb == 0) %>% 
  pull(n)

```


```{r missing2}

appx_list$na_interpret_affected <- UpSetR::upset(appx_list$upset_data)

n_cutoff <- 5
plotdta <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing)) %>% 
  ungroup() 

appx_list$plot_mis_dir_nonmis_sub <- plotdta %>% 
  slice(1:20) %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(official_suburb, percentage_missing), size = n_missing))+
  labs(title = "Fig. B: Top 20 Suburbs with missing Directorate")

# missing directorate and dates

appx_list$table_mis_dir_dates <- dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, is.na(directorate)) %>% 
               count(name = "n_missing")) %>%
  ungroup() %>% 
  rename(missing_directorate = 4) %>% 
  filter(missing_directorate == TRUE) %>% 
  mutate(percentage_missing = n_missing/total_ym*100) %>% 
  kable(format = "simple") %>%
   kable_styling(position = "left")

```


```{r missing3}
# Of the entries with Official suburb missing, ...

plotdta <- dta %>% 
  group_by(directorate) %>% 
  count(name = "total_directorate") %>%
  inner_join(dta %>% 
               filter(is.na(official_suburb)) %>% 
               group_by(directorate) %>% 
                        count(name = "n_missing")) %>% 
  ungroup() %>% 
  mutate(percentage_missing = n_missing/total_directorate*100)

appx_list$mis_sub <- plotdta %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(directorate, percentage_missing), size = n_missing))+
  labs(title = "Fig. C: Missing Suburbs per Directorate")

```


```{r missing4}

# Missingness in specific directorate

dta_dir <- dta %>% 
  filter(directorate == select_directorate)

x <- which(names(dta_dir) %in% c("code_group", "code", "cause_code_group", "cause_code"))

# map(dta_dir[x], ~sort(unique(.x))) 
# map(dta_dir[x], ~sum(is.na(.x))) 
# 
# dta_dir %>%
#   select(all_of(x)) %>% 
#   group_by(is.na(.)) %>% 
#   count()

x <- nrow(dta_dir)

x1 <- dta_dir %>% 
  group_by(mis_code_grp = is.na(cause_code_group), 
           mis_cause_code = is.na(cause_code)) %>% 
  count(name = "missing_cause") %>% 
  ungroup() %>% 
  filter(mis_code_grp == TRUE & mis_cause_code == TRUE) %>% 
  pull(missing_cause)

appx_list$miss_cause <- tibble(msg = glue::glue("Missing cause for {round(x1/x*100, 2)}% of {select_directorate} entries.")) %>%
  kable(col.names = NULL) %>%
  kable_styling(position = "left")


```



```{r missing5}
# Missing completion dates for `r select_directorate`.
appx_list$miss_compl_dates <- dta_dir %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            missing_completion_time = 
              sum(is.na(completion_timestamp))) %>% 
  filter(missing_completion_time != 0) %>% 
  kable(format = "simple") %>%
  kable_styling(position = "left")


```



```{r prep}

# prepare ----------------------------------------------------------

  # exclusions -------

# exclude creation date 2019, as only 31 Dec is represented

dta <- dta %>% 
  filter(creation_timestamp >= lubridate::as_datetime("2020-01-01 00:00:00 UTC"))

# Exclude if missing directorate

dta <- dta %>% 
  filter(!is.na(directorate))

```

## Overview of all Directorates

This section provides broad context of service requests across all COCT Directorates for the time period included in the dataset. The table displays number of service requests per Directorate, as well as the percentage each represents of the total requests for all Directorates. The Urban Mobility Directorate requests make up a small percentage of total requests.

```{r overview}
x <- nrow(dta)
 
tmp <- dta %>% 
  group_by(directorate) %>% 
  count(name = "Nr_of_entries") %>% 
  mutate(Percentage_of_total = round(Nr_of_entries/x*100, 2)) %>% 
  arrange(desc(Nr_of_entries)) %>% 
  rename(Directorate = directorate) 

x <- which(tmp$Directorate == select_directorate)


tmp %>% 
  kable(format = "simple", caption = "Number and percentage of entries per Directorate") %>%
  kable_styling( position = "left") %>% 
  row_spec(row = x, bold = TRUE)

```

The percentages of total requests seem to remain fairly stable per month, in the included time period, with Water and Sanitation and Energy contributing the bulk of requests.

```{r}
dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, directorate) %>% 
               count(name = "Nr_of_entries")) %>% 
  ungroup() %>% 
  mutate(Percentage_of_total = round(Nr_of_entries/total_ym*100, 2)) %>% 
  arrange(desc(Nr_of_entries)) %>% 
  ggplot(aes(month_creation, Percentage_of_total, 
             fill = reorder(directorate, Percentage_of_total)))+
  geom_col()+
  facet_wrap(~year_creation, scales = "free_x")+
  labs(fill = "Directorate, ordered from smallest to largest contribution",
       x = "Month", y = "Percentage of total requests")

tmp <- dta %>% 
  filter(!is.na(official_suburb)) %>% 
  group_by(directorate) %>% 
  count(name = "total_directorate") %>% 
  inner_join(dta %>% 
               filter(!is.na(official_suburb)) %>% 
               group_by(directorate, official_suburb) %>% 
               count(name = "total_suburb")) %>% 
  mutate(percentage = total_suburb/total_directorate*100) 

```

Highlighting the top 3 suburbs (largest percentage of total per suburb) for each Directorate, reveals that for most Directorates the total requests are made up of many suburbs, contributing relatively low proportions to the total. For Urban Mobility, for example, the biggest contribution is Milnerton, around 4%, which means that many other suburbs contribute percentages lower than 4%, to make up the total of requests for this Directorate.  The only exception is The Human Settlements Directorate where the top 3 suburbs, together, contribute around 30% of the total.   

```{r}
map(unique(tmp$directorate),
    ~tmp %>% 
      filter(directorate == .x) %>% 
      arrange(desc(percentage)) %>% 
      slice(1:3)) %>% 
  bind_rows() %>% 
  ggplot(aes(percentage, official_suburb, fill = directorate))+
  geom_col()+
  facet_wrap(~directorate, scales = "free_y",
             nrow = 2)+
  theme(legend.position = "none")

```

## Focused Analysis: Directorate `r select_directorate`

This section provides insight to inform decisions for infrastructure improvement efforts.  It is important to note that the suburb information was missing for a large percentage of service requests (Table x).   

```{r focused1}

# Number of requests over time, including missing suburbs,
# including missing completion times

# dta_dir %>% 
#   group_by(year_creation, month_creation) %>% 
#   count()
  
# % suburb missing

dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta_dir %>% 
               filter(is.na(official_suburb)) %>% 
               group_by(year_creation, month_creation) %>% 
               count(name = "total_missing")) %>% 
  mutate(percentage_missing_suburb = round(total_missing/total_ym*100, 2)) %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")
  
```

The reason for the suburb missingness is not clear from the data.  For the top 5 codes with most service requests, "Pothole&Defect Road Foot Bic Way/Kerbs" and "Paint Markings Lines&Signs" were more likely to be missing, than not (Table x).  

```{r focused2}
dta_dir %>% 
  group_by(code) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(desc(n)) %>% 
  slice(1:5) %>% 
  select(-n) %>% 
  inner_join(dta_dir %>% 
  group_by(mis_sub = is.na(official_suburb), code) %>% 
  count()) %>% 
  pivot_wider(names_from = mis_sub, values_from = n) %>% 
  print(n = Inf)

```

The odds of a suburb entry being missing was more than double for a number of dates, the top 4 of which occur closely together in March 2020 (Table x).  There may therefore be a systematic reason for this missingness, but it is not clear from this dataset.  

```{r focused5}

dta_dir %>% 
  mutate(across(creation_timestamp, ~as_date(.x))) %>% 
  group_by(creation_timestamp, mis_sub = is.na(official_suburb)) %>% 
  count() %>% 
  ungroup() %>% 
  pivot_wider(names_from = mis_sub, values_from = n) %>% 
  rename(missing = `TRUE`, not_missing = `FALSE`) %>% 
  mutate(odds = round(missing/not_missing, 2)) %>% 
  arrange(desc(odds)) %>% 
  slice(1:5) %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")

tmp <- dta_dir %>% 
  mutate(across(creation_timestamp, ~as_date(.x))) %>% 
  group_by(creation_timestamp, mis_sub = is.na(official_suburb)) %>% 
  count() %>% 
  ungroup() %>% 
  filter(mis_sub == TRUE) %>% 
  arrange(desc(n))

x <- sum(tmp$n)

x <- tmp %>% 
  slice(1:5) %>% 
  summarise(perc = sum(n)/x*100)


```

The top 5 dates for missing suburb entries, represent `r x`% of all the missing suburb entries.  

Service requests with missing suburb entries were excluded for the rest of this analysis, but it should be kept in mind that a systematic cause for the missingness may influence the interpretation of these results.  An important action point may therefore be to attempt to find the cause for the large proportion of missing suburb entries.  

```{r focused4}

# START HERE
# exclude missing suburb

dta_dir <- dta_dir %>% 
  filter(!is.na(official_suburb))


# nr over time, per suburb, missing suburbs excluded now


tmp <- dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta_dir %>% 
               group_by(year_creation, 
                        month_creation, official_suburb) %>% 
  count(name = "total_suburb")) %>% 
  mutate(percentage_suburb = total_suburb/total_ym*100) %>% 
  arrange(year_creation, month_creation,
          desc(percentage_suburb))

grid <- expand_grid(yr = unique(tmp$year_creation),
                    mnth = unique(tmp$month_creation))

tmp <- map2(grid$yr, grid$mnth,
     ~tmp %>% 
       filter(year_creation == .x & month_creation == .y) %>% 
       arrange(desc(percentage_suburb)) %>% 
       slice(1:5)) %>% 
  bind_rows()

tmp %>% 
  ggplot(aes(percentage_suburb, reorder(official_suburb, percentage_suburb), fill = month_creation))+
  geom_col()+
  facet_wrap(~year_creation + month_creation,
             scales = "free_y")


# department, branch, section, code_group not helpful
# dta_dir %>% 
#   group_by(code, cause_code) %>% 
#   count() %>% 
#   print(n = Inf)

# many cause codes NA, use code var only

x <- nrow(dta_dir)

tmp <- dta_dir %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  mutate(percentage_suburb = total_suburb/x*100) %>% 
  arrange(desc(percentage_suburb)) %>% 
  ungroup() %>% 
  slice(1:20) 

tmp %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")

#  

tmp <- dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_month") %>% 
  inner_join(dta_dir %>% 
  group_by(year_creation, month_creation, official_suburb) %>% 
  count(name = "total_suburb")) %>% 
  ungroup() %>% 
    mutate(percentage = total_suburb/total_month*100) %>% 
    arrange(year_creation, month_creation, desc(percentage)) %>% 
  select(year_creation, month_creation, official_suburb,
         percentage) %>% 
    pivot_wider(names_from = month_creation, values_from = percentage) %>%  # add median across months
inner_join(dta_dir %>% 
             group_by(month_creation) %>% 
             count(name = "total_month") %>% 
             inner_join(dta_dir %>% 
  group_by(month_creation, official_suburb) %>% 
  count()) %>% 
  ungroup() %>% 
    mutate(percentage_suburb = n/total_month*100) %>% 
    group_by(official_suburb) %>% 
  summarise(med_percentage = median(percentage_suburb)) %>% 
  ungroup()) %>% 
  inner_join(tmp %>% 
               select(official_suburb)) %>% 
  arrange(desc(med_percentage)) 

tmp %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")

# explore codes for top 5

x <- tmp$official_suburb[1:5]

dta_dir %>% 
  filter(official_suburb %in% x) %>% 
  group_by(official_suburb, code) %>% 
  count() %>% 
  ungroup() %>% 
  ggplot(aes(n, code, fill = official_suburb))+
  geom_col(position = "dodge")

# top 3


select_suburbs <- c("PARKLANDS", "MILNERTON")

```



## 1. Focusing on the Urban Mobility directorate - "What is the median & 80th percentile time to complete each service request across the City?" (each row represent a service request).

```{r}

# exclude data with no completion time, create diff var

dta_dir <- dta_dir %>% 
  filter(!is.na(completion_timestamp)) 

```


```{r}

# summary(dta_dir$time_hours)

# check for outliers in time_hours

# tmp <- dta_dir %>%
#   summarise(q25 = quantile(time_hours, probs = 0.25),
#             q75 = quantile(time_hours, probs = 0.75),
#             iqr = q75 - q25,
#             ol_cutoff = 1.5*iqr + q75)
# 
# dta_dir %>% 
#   group_by(time_hours > tmp$ol_cutoff) %>% 
#   count()
# 
# dta_dir %>% 
#   filter(time_days >= tmp$ol_cutoff) %>% 
#   ggplot(aes(time_hours, official_suburb, 
#              colour = official_suburb))+
#   geom_jitter()+
#   facet_wrap(~code, scales = "free_y")+
#   theme(legend.position = "none")


#  create table with medians, q80 for all suburbs and for all of city 

time_tables_make <- function(dataset = dta_dir, time_cutoff = NULL){
  
  sub_txt <- "ALL COMBINED"
  code_txt <- "All codes combined"
  
  if(is.null(time_cutoff)){
  
  tabledta <- dataset %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
                 mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup())

  return(tabledta)
  
} else if(!is.null(time_cutoff)){
  
  dataset_x <- dataset %>% 
    filter(time_hours < time_cutoff)
  
  tabledta_below <- dataset_x %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset_x %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
              mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup())
  
  dataset_x <- dataset %>% 
    filter(time_hours >= time_cutoff)
  
  tabledta_above <- dataset_x %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset_x %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
              mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup())
  
  return(list(tabledta_below = tabledta_below,
                tabledta_above = tabledta_above))
}
}

time_dta_list <- list()

# for all of city, all codes, all completion time lengths

time_dta_list$all_times <- time_tables_make(dataset = dta_dir, time_cutoff = NULL)

# for all of city, all codes, split by times < or > 24hrs
tmp <- time_tables_make(dataset = dta_dir, time_cutoff = 24)

time_dta_list$below_24 <- tmp$tabledta_below 
time_dta_list$above_eq_24 <- tmp$tabledta_above 

# look at suburbs with n >= 5
# all codes combined

n_cutoff <- 5
sub_txt <- "ALL COMBINED"
code_txt <- "All codes combined"

time_dta_list$all_times %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(format = "simple", caption = "City-wide, all codes combined") %>%
  kable_styling( position = "left")

# filter by < 24 hrs

time_dta_list$below_24 %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(format = "simple", caption = "City-wide, all codes combined, only requests completed in less than 24 hours") %>%
  kable_styling( position = "left")

# > 24 hrs

time_dta_list$above_eq_24 %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(format = "simple", caption = "City-wide, all codes combined, only requests completed in 24 hours or more") %>%
  kable_styling( position = "left")

# split by 24 hours

x <- time_dta_list$below_24 %>% 
  filter(official_suburb == "ALL COMBINED" &
           code == "All codes combined") %>% 
  pull(n)

x <- time_dta_list$all_times %>% 
  filter(official_suburb == "ALL COMBINED" &
           code == "All codes combined") %>% 
  mutate(perc = x/n*100) %>% 
  pull(perc)
  
# x

time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  arrange(desc(med_time_hours)) %>% 
  slice(1:5) %>% 
  kable(format = "simple", caption = "Top 5 suburbs with longest median completion times, all codes combined") %>%
  kable_styling( position = "left")

time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  arrange(med_time_hours) %>% 
  slice(1:5) %>% 
  kable(format = "simple", caption = "Top 5 suburbs with shortest median completion times, all codes combined") %>%
  kable_styling(position = "left")



# split by codes
# codes with > 5 requests, per suburb
# show top 5 per code

# get codes for which > 5 requests for some suburbs

n_cutoff <- 5

x <- dta_dir %>% 
  group_by(code, official_suburb) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  filter(n >= n_cutoff) %>% 
  ungroup() %>% 
  distinct(code) %>% 
  pull(code)

sub_txt <- "ALL COMBINED"
time_cutoff <- 24

p1 <- map(x,
    ~time_dta_list$below_24 %>% 
  filter(official_suburb != sub_txt &
           code == .x &
           n >= n_cutoff) %>% 
  select(official_suburb, code) %>% 
    distinct() %>% 
    inner_join(dta_dir %>% 
                 filter(time_hours < time_cutoff))) %>% 
  bind_rows() %>% 
  ggplot(aes(time_hours, official_suburb))+
    ggdist::stat_interval()+
  facet_wrap(~code, scales = "free_y", ncol = 1)


p2 <- map(x,
    ~time_dta_list$above_eq_24 %>% 
  filter(official_suburb != sub_txt &
           code == .x &
           n >= n_cutoff) %>% 
  select(official_suburb, code) %>% 
    distinct() %>% 
    inner_join(dta_dir %>% 
                 filter(time_hours >= time_cutoff))) %>% 
  bind_rows() %>% 
  ggplot(aes(time_hours, official_suburb))+
    ggdist::stat_interval()+
  facet_wrap(~code, scales = "free_y",
             ncol = 1)

ggpubr::ggarrange(p1, p2, ncol = 1, nrow = 2,
                  heights = c(2,1))

tmp <- map(x,
           ~time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == .x &
           n >= n_cutoff) %>% 
  arrange(desc(med_time_hours))) 

x <- seq(1,length(tmp), by = 2)

kable(tmp[1:2], format = "simple") %>%
    kable_styling( position = "left")



# per month




# weekends, public holidays?

```



## 2. Focusing on the Urban Mobility directorate - "What is the median & 80th percentile time to complete each service request for the 3 suburbs identified in (1)?" (each row represent a service request).



## 3. "Is there any significant differences in the median and 80th percentile completion times between the City as a whole and the 3 suburbs identified in(1)?".  Please elaborate on the similarities or differences.

```{r}


time_dta_list$all_times %>% 
  filter(official_suburb %in% c(select_suburbs, "ALL COMBINED")) 

# wilcox test
map(select_suburbs,
    ~dta_dir %>% 
  select(official_suburb, time_hours) %>%
  mutate(suburb_bin = case_when(official_suburb %in% 
                                  .x ~ .x,
                                TRUE ~ "ALL COMBINED")) %>% 
  summarise(suburb = .x,
            p_value = wilcox.test(time_hours ~ 
                                    suburb_bin)$p.value))

# prop.test

prop_test_list <- list()

for(i in 1:length(select_suburbs)){
x <- time_dta_list$all_times %>% 
  filter(official_suburb %in% "ALL COMBINED" &
           code == "All codes combined") %>% 
  pull(med_time_hours)

tmp <- dta_dir %>% 
  select(official_suburb, time_hours) %>%
  mutate(med_compare = case_when(time_hours < x ~ "below_coct_median",
                                time_hours >= x ~ "above_or_eq_coct_med")) %>% 
  mutate(suburb_bin = case_when(official_suburb %in% 
                                  select_suburbs[i] ~ select_suburbs[i],
                                TRUE ~ "ALL COMBINED")) %>% 
  group_by(med_compare, suburb_bin) %>% 
  count() %>% 
  pivot_wider(names_from = med_compare, values_from = n) %>% 
  ungroup() %>% 
  select(-suburb_bin) 

prop_test_list[[i]] <- tibble(suburb = select_suburbs[i],
       p_value = prop.test(as.matrix(tmp))$p.value)

}

prop_test_list

```


## 3. Provide a visual mock of a dashboard for the purpose of monitoring progress in applying the insights developed in (1) & (2). It should focus the user on performance pain points. Add a note for each visual element, explaining how it helps fulfill this overall function. Please also provide a brief explanation as to how the data provided would be used to realise what is contained in your mock.


## 4. Identify value-adding insights for the management of Urban Mobility, from the dataset provided, in regard to commuter transport within the City.
 
 
```{r}
# traffic congestion over time
 
 unique(dta_dir$code)
 
 code_txt <- "Conjested Traffic at Intersection"
 
tmp <- dta_dir %>% 
 mutate(across(creation_timestamp, ~as_date(.x))) %>% 
 filter(code == code_txt) %>% 
 group_by(code,creation_timestamp) %>% 
 count() %>% 
 ungroup() 

x <- sort(tmp$n, decreasing = TRUE)
x <- x[6]

tmp %>% 
mutate(day_of_week = wday(creation_timestamp, label=TRUE),
       label = case_when(n > x ~ 
                           paste(day_of_week, creation_timestamp),
                         TRUE ~ "")) %>% 
   
 ggplot(aes(creation_timestamp, n, group = code,
            label = label))+
 geom_line(colour = "grey70")  +
 geom_point()+
   geom_text()

dta_dir %>% 
 mutate(create_date = as_date(creation_timestamp)) %>% 
 filter(code == code_txt) %>% 
 group_by(code,create_date) %>% 
 count() %>% 
 ungroup() %>% 
  filter(n > x) %>% 
  select(-n) %>% 
  inner_join(dta_dir) %>% 
  group_by(create_date,official_suburb) %>% 
  count() %>% 
  ungroup() %>% 
  ggplot(aes(n, reorder(official_suburb,n), fill = as.factor(create_date)))+
  geom_col()

 
 
 # which days of the week have more traffic congestion reports
 
 x <- dta_dir %>% 
   group_by(code) %>% 
   count() %>% 
   arrange(desc(n)) %>% 
   ungroup() %>% 
   slice(1:5) %>% 
   pull(code)
 
 dta_dir %>% 
   filter(code %in% x) %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 group_by(code, day_of_week) %>% 
 count() %>%
   ggplot(aes(day_of_week, n, group = code, colour = code))+
 geom_point()+
 geom_line()
   
 
 dta_dir %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 filter(code == code_txt) %>% 
 group_by(day_of_week) %>% 
 count() %>% 
 ggplot(aes(day_of_week, n))+
 geom_col()
 
 # ?stats
 # odds of having congestion on a wednesday vs other weekdays
 
 
 # suburbs and days of week
 
x <-  dta_dir %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 group_by(day_of_week, official_suburb) %>% 
 count() %>% 
   ungroup() %>% 
   arrange(desc(n)) %>% 
   slice(1:10) %>% 
   pull(n)
 
x <- x[length(x)] 

sz <- 3
 dta_dir %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 group_by(day_of_week, official_suburb) %>% 
 count() %>% 
   mutate(label = case_when(n >= x ~ official_suburb,
                          TRUE ~ "")) %>% 
   ggplot(aes(day_of_week, n, label = label))+
   geom_point(alpha = 0.6)+
   geom_text(alpha = 0.5, size = sz, check_overlap = TRUE)
 
```
 
## Appendix


```{r}

#### Missingness - include these results in appendix
# save in appendix list
appx_list <- list()

n_cutoff <- 5

appx_list$miss_dir <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing), desc(n_missing)) %>% 
  ungroup()

# max(tmp$percentage_missing)
# tmp$official_suburb[tmp$percentage_missing == max(tmp$percentage_missing)]

appx_list$upset_data <- dta %>% 
  select(directorate, department, branch, section, official_suburb) %>% 
  mutate(across(everything(), ~as.numeric(is.na(.x)))) %>% 
  as.data.frame()


appx_list$mis_dir_nonmis_sub <- appx_list$upset_data %>% 
  group_by(directorate, official_suburb) %>% 
  count() %>% 
  filter(directorate == 1 & official_suburb == 0) %>% 
  pull(n)

```

Missingness of specific data entries can be meaningful, e.g. it can point to operational failures if a specific region has more missing data than another.  Therefore it is important to interrogate patterns of missingness in data. We investigated missingness that would make interpretation hard.  Entries for which any of the Directorate, Department, Branch, Section or Official suburb were missing are visualised (Figure A). Entries with missing Directorate were in general also missing for the other categories. Suburbs for which there were at least `r n_cutoff` entries, and for which Directorate was missing, but Official suburb was not(n = `r mis_dir_nonmis_sub`), accounted for at most `r max(tmp1$percentage_missing)` of entries for any suburb and the suburb with the highest percentage of missing entries of this kind, was `r tmp1$official_suburb[tmp1$percentage_missing == max(tmp1$percentage_missing)]`(Figure B). 

```{r}

appx_list$na_interpret_affected <- UpSetR::upset(tmp)

na_interpret_affected
grid::grid.text("Fig. A",x = 0.65, y=0.95, gp=grid::gpar(fontsize=20))

n_cutoff <- 5
plotdta <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing)) %>% 
  ungroup() 

appx_list$plot_mis_dir_nonmis_sub <- plotdta %>% 
  slice(1:20) %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(official_suburb, percentage_missing), size = n_missing))+
  labs(title = "Fig. B: Top 20 Suburbs with missing Directorate")

# missing directorate and dates

appx_list$table_mis_dir_dates <- dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, is.na(directorate)) %>% 
               count(name = "n_missing")) %>%
  ungroup() %>% 
  rename(missing_directorate = 4) %>% 
  filter(missing_directorate == TRUE) %>% 
  mutate(percentage_missing = n_missing/total_ym*100) %>% 
  kable(format = "simple") %>%
   kable_styling(position = "left")

```

Of the entries with Official suburb missing, ...

```{r}

plotdta <- dta %>% 
  group_by(directorate) %>% 
  count(name = "total_directorate") %>%
  inner_join(dta %>% 
               filter(is.na(official_suburb)) %>% 
               group_by(directorate) %>% 
                        count(name = "n_missing")) %>% 
  ungroup() %>% 
  mutate(percentage_missing = n_missing/total_directorate*100)

appx_list$mis_sub <- plotdta %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(directorate, percentage_missing), size = n_missing))+
  labs(title = "Fig. C: Missing Suburbs per Directorate")

```

Missingness in specific directorate

```{r}

# Missingness in specific directorate

dta_dir <- dta %>% 
  filter(directorate == select_directorate)

x <- which(names(dta_dir) %in% c("code_group", "code", "cause_code_group", "cause_code"))

# map(dta_dir[x], ~sort(unique(.x))) 
# map(dta_dir[x], ~sum(is.na(.x))) 
# 
# dta_dir %>%
#   select(all_of(x)) %>% 
#   group_by(is.na(.)) %>% 
#   count()

x <- nrow(dta_dir)

x1 <- dta_dir %>% 
  group_by(mis_code_grp = is.na(cause_code_group), 
           mis_cause_code = is.na(cause_code)) %>% 
  count(name = "missing_cause") %>% 
  ungroup() %>% 
  filter(mis_code_grp == TRUE & mis_cause_code == TRUE) %>% 
  pull(missing_cause)

appx_list$miss_cause <- tibble(msg = glue::glue("Missing cause for {round(x1/x*100, 2)}% of {select_directorate} entries.")) %>%
  kable(col.names = NULL) %>%
  kable_styling(position = "left")


```

Missing completion dates for `r select_directorate`.

```{r}

appx_list$miss_compl_dates <- dta_dir %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            missing_completion_time = 
              sum(is.na(completion_timestamp))) %>% 
  filter(missing_completion_time != 0) %>% 
  kable(format = "simple") %>%
  kable_styling(position = "left")


```



 
 
 
 
```{r} 
 
sessionInfo() 
 
```
 
 