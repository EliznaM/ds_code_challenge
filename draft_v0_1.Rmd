---
title: "COCT Urban Mobility"
output: pdf_document
author:  "E Maasdorp"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[width=2in,height=2in]{img/city_emblem.png}\LARGE\\}
  - \posttitle{\end{center}}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.height = 16, fig.width = 20)
```

## Overview

**Note from the author:  This report was compiled to complete the City of Cape Town (COCT) data science challenge.  It is not an official COCT report.**  
The goal of this analysis was to highlight COCT suburbs that the Urban Mobility Directorate should focus on, for infrastructure improvements, based on service request data for 4 months (December 2020 to March 2021). It also explored intervals between creation and completion of service requests, to identify performance across the city. Finally, a suggested performance tracking dashboard is provided, and insights are provided to aid   

```{r setup2}

# libraries
library(kableExtra)
library(knitr)
library(lubridate)
library(tidyverse)

# colours and theme
  # COCT colours

coct_cols <- c("#C7006E", "#B9CF00","#00A6CD", "#FF9900",  "#000000")

theme_set(theme_light())

# functions


# parameters

select_directorate <- "URBAN MOBILITY"
# specify the Directorate this analysis focuses on

```

## Methods

Describe data prep, code generalisable, tech details - missingness, exclusion decisions, choice of vars (e.g. code var).

```{r data_prep, results='hide'}
# output from this code chunk should not print in report

# read file from local

dta <- read_csv("data/sr_hex_truncated.csv")

# data checks ----------------------------------------

glimpse(dta)

sum(is.na(dta$notification_number))
# no missing notification nrs

length(dta$notification_number) == length(unique(dta$notification_number))
# each row is unique entry


  # numeric cols ---------

summary(dta$latitude)
summary(dta$longitude)
  
  # date cols -----------

unique(lubridate::as_date(dta$creation_timestamp)) 
# none missing
# exlude 1 date in dec-2019
unique(lubridate::as_date(dta$completion_timestamp))
# some NAs, explore later

# create new variables -----------------------------------------

  # make month and year columns ------

dta <- dta %>% 
  mutate(year_creation = lubridate::year(creation_timestamp),
         month_creation = lubridate::month(creation_timestamp),
         year_completion = lubridate::year(completion_timestamp),
         month_completion = lubridate::month(completion_timestamp))

mnths <- c("jan", "feb", "mar", "apr", "may", "jun", "jul",
           "aug", "sep", "oct", "nov", "dec")

dta$month_creation <- factor(dta$month_creation, levels = 1:12,  labels = mnths)
dta$month_completion <- factor(dta$month_completion, levels = 1:12, labels = mnths)

  # make time-to-complete columns ------
  # note %--% is a lubridate-specific operator

dta <- dta %>% 
   mutate(interv = creation_timestamp %--% completion_timestamp,
          time_hours = as.duration(interv) / dhours(1),
          time_days = as.duration(interv) / ddays(1),
          time_weeks = as.duration(interv) / dweeks(1)) %>% 
  select(-interv)
  
```


#### Missingness

```{r missing1}

n_cutoff <- 5

tmp1 <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing), desc(n_missing)) %>% 
  ungroup()

# max(tmp$percentage_missing)
# tmp$official_suburb[tmp$percentage_missing == max(tmp$percentage_missing)]

tmp <- dta %>% 
  select(directorate, department, branch, section, official_suburb) %>% 
  mutate(across(everything(), ~as.numeric(is.na(.x)))) %>% 
  as.data.frame()


mis_dir_nonmis_sub <- tmp %>% 
  group_by(directorate, official_suburb) %>% 
  count() %>% 
  filter(directorate == 1 & official_suburb == 0) %>% 
  pull(n)

```

Missingness of specific data entries can be meaningful, e.g. it can point to operational failures if a specific region has more missing data than another.  Therefore it is important to interrogate patterns of missingness in data. We investigated missingness that would make interpretation hard.  Entries for which any of the Directorate, Department, Branch, Section or Official suburb were missing are visualised (Figure A). Entries with missing Directorate were in general also missing for the other categories. Suburbs for which there were at least `r n_cutoff` entries, and for which Directorate was missing, but Official suburb was not(n = `r mis_dir_nonmis_sub`), accounted for at most `r max(tmp1$percentage_missing)` of entries for any suburb and the suburb with the highest percentage of missing entries of this kind, was `r tmp1$official_suburb[tmp1$percentage_missing == max(tmp1$percentage_missing)]`(Figure B). 

```{r missing2}

na_interpret_affected <- UpSetR::upset(tmp)

na_interpret_affected
grid::grid.text("Fig. A",x = 0.65, y=0.95, gp=grid::gpar(fontsize=20))

n_cutoff <- 5
plotdta <- dta %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  inner_join(dta %>% 
  filter(is.na(directorate) & !is.na(official_suburb)) %>% 
  group_by(official_suburb) %>% 
  count(name = "n_missing")) %>% 
  mutate(percentage_missing = n_missing/total_suburb*100) %>% 
  filter(n_missing >= n_cutoff) %>% 
  arrange(desc(percentage_missing)) %>% 
  ungroup() 

plotdta %>% 
  slice(1:20) %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(official_suburb, percentage_missing), size = n_missing))+
  labs(title = "Fig. B: Top 20 Suburbs with missing Directorate")

# missing directorate and dates

dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, is.na(directorate)) %>% 
               count(name = "n_missing")) %>%
  ungroup() %>% 
  rename(missing_directorate = 4) %>% 
  filter(missing_directorate == TRUE) %>% 
  mutate(percentage_missing = n_missing/total_ym*100) %>% 
  kable(format = "simple") %>%
   kable_styling(position = "left")

```

Of the entries with Official suburb missing, ...

```{r}

plotdta <- dta %>% 
  group_by(directorate) %>% 
  count(name = "total_directorate") %>%
  inner_join(dta %>% 
               filter(is.na(official_suburb)) %>% 
               group_by(directorate) %>% 
                        count(name = "n_missing")) %>% 
  ungroup() %>% 
  mutate(percentage_missing = n_missing/total_directorate*100)

plotdta %>% 
  ggplot()+
  geom_point(aes(percentage_missing, reorder(directorate, percentage_missing), size = n_missing))+
  labs(title = "Fig. C: Missing Suburbs per Directorate")

```

Missingness in specific directorate

```{r}

# Missingness in specific directorate

dta_dir <- dta %>% 
  filter(directorate == select_directorate)

x <- which(names(dta_dir) %in% c("code_group", "code", "cause_code_group", "cause_code"))

# map(dta_dir[x], ~sort(unique(.x))) 
# map(dta_dir[x], ~sum(is.na(.x))) 
# 
# dta_dir %>%
#   select(all_of(x)) %>% 
#   group_by(is.na(.)) %>% 
#   count()

x <- nrow(dta_dir)

x1 <- dta_dir %>% 
  group_by(mis_code_grp = is.na(cause_code_group), 
           mis_cause_code = is.na(cause_code)) %>% 
  count(name = "missing_cause") %>% 
  ungroup() %>% 
  filter(mis_code_grp == TRUE & mis_cause_code == TRUE) %>% 
  pull(missing_cause)

# tibble(msg = glue::glue("Missing cause for {round(x1/x*100, 2)}% of {select_directorate} entries.")) %>% 
#   kable(col.names = NULL) %>%
#   kable_styling(full_width = FALSE, position = "left")


```

Missing completion dates for `r select_directorate`.

```{r}

dta_dir %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            missing_completion_time = 
              sum(is.na(completion_timestamp))) %>% 
  filter(missing_completion_time != 0) %>% 
  kable(format = "simple") %>%
  kable_styling(position = "left")


```



```{r}

# prepare ----------------------------------------------------------

  # exclusions -------

# exclude creation date 2019, as only 31 Dec is represented

dta <- dta %>% 
  filter(creation_timestamp >= lubridate::as_datetime("2020-01-01 00:00:00 UTC"))

# Exclude if missing directorate

dta <- dta %>% 
  filter(!is.na(directorate))

```

## Overview of all Directorates

Contextualise

```{r overview}
x <- nrow(dta)
 
tmp <- dta %>% 
  group_by(directorate) %>% 
  count(name = "Nr_of_entries") %>% 
  mutate(Percentage_of_total = round(Nr_of_entries/x*100, 2)) %>% 
  arrange(desc(Nr_of_entries)) %>% 
  rename(Directorate = directorate) 

x <- which(tmp$Directorate == select_directorate)

tmp %>% 
  kable(format = "simple", caption = "Number and percentage of entries per Directorate") %>%
  kable_styling( position = "left") %>% 
  row_spec(row = x, bold = TRUE)

dta %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta %>% 
               group_by(year_creation, month_creation, directorate) %>% 
               count(name = "Nr_of_entries")) %>% 
  ungroup() %>% 
  mutate(Percentage_of_total = round(Nr_of_entries/total_ym*100, 2)) %>% 
  arrange(desc(Nr_of_entries)) %>% 
  ggplot(aes(month_creation, Percentage_of_total, 
             fill = reorder(directorate, Percentage_of_total)))+
  geom_col()+
  facet_wrap(~year_creation, scales = "free_x")

tmp <- dta %>% 
  filter(!is.na(official_suburb)) %>% 
  group_by(directorate) %>% 
  count(name = "total_directorate") %>% 
  inner_join(dta %>% 
               filter(!is.na(official_suburb)) %>% 
               group_by(directorate, official_suburb) %>% 
               count(name = "total_suburb")) %>% 
  mutate(percentage = total_suburb/total_directorate*100) 

map(unique(tmp$directorate),
    ~tmp %>% 
      filter(directorate == .x) %>% 
      arrange(desc(percentage)) %>% 
      slice(1:3)) %>% 
  bind_rows() %>% 
  ggplot(aes(percentage, official_suburb, fill = directorate))+
  geom_col()+
  facet_wrap(~directorate, scales = "free_y",
             nrow = 2)+
  theme(legend.position = "none")

```

## Focused Analysis: Directorate `r select_directorate`

## "In which 3 suburbs should the Urban Mobility directorate concentrate their infrastructure improvement efforts?"

```{r}

# Number of requests over time, including missing suburbs,
# including missing completion times

dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count()
  
# % suburb missing

dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta_dir %>% 
               filter(is.na(official_suburb)) %>% 
               group_by(year_creation, month_creation) %>% 
               count(name = "total_missing")) %>% 
  mutate(percentage_missing_suburb = round(total_missing/total_ym*100, 2)) %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")
  
# exclude missing suburb

dta_dir <- dta_dir %>% 
  filter(!is.na(official_suburb))


# nr over time, per suburb, missing suburbs excluded now


tmp <- dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_ym") %>% 
  inner_join(dta_dir %>% 
               group_by(year_creation, 
                        month_creation, official_suburb) %>% 
  count(name = "total_suburb")) %>% 
  mutate(percentage_suburb = total_suburb/total_ym*100) %>% 
  arrange(year_creation, month_creation,
          desc(percentage_suburb))

grid <- expand_grid(yr = unique(tmp$year_creation),
                    mnth = unique(tmp$month_creation))

tmp <- map2(grid$yr, grid$mnth,
     ~tmp %>% 
       filter(year_creation == .x & month_creation == .y) %>% 
       arrange(desc(percentage_suburb)) %>% 
       slice(1:5)) %>% 
  bind_rows()

tmp %>% 
  ggplot(aes(percentage_suburb, reorder(official_suburb, percentage_suburb), fill = month_creation))+
  geom_col()+
  facet_wrap(~year_creation + month_creation,
             scales = "free_y")


# department, branch, section, code_group not helpful
# dta_dir %>% 
#   group_by(code, cause_code) %>% 
#   count() %>% 
#   print(n = Inf)

# many cause codes NA, use code var only

x <- nrow(dta_dir)

tmp <- dta_dir %>% 
  group_by(official_suburb) %>% 
  count(name = "total_suburb") %>% 
  mutate(percentage_suburb = total_suburb/x*100) %>% 
  arrange(desc(percentage_suburb)) %>% 
  ungroup() %>% 
  slice(1:20) 

tmp %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")

#  

tmp <- dta_dir %>% 
  group_by(year_creation, month_creation) %>% 
  count(name = "total_month") %>% 
  inner_join(dta_dir %>% 
  group_by(year_creation, month_creation, official_suburb) %>% 
  count(name = "total_suburb")) %>% 
  ungroup() %>% 
    mutate(percentage = total_suburb/total_month*100) %>% 
    arrange(year_creation, month_creation, desc(percentage)) %>% 
  select(year_creation, month_creation, official_suburb,
         percentage) %>% 
    pivot_wider(names_from = month_creation, values_from = percentage) %>%  # add median across months
inner_join(dta_dir %>% 
             group_by(month_creation) %>% 
             count(name = "total_month") %>% 
             inner_join(dta_dir %>% 
  group_by(month_creation, official_suburb) %>% 
  count()) %>% 
  ungroup() %>% 
    mutate(percentage_suburb = n/total_month*100) %>% 
    group_by(official_suburb) %>% 
  summarise(med_percentage = median(percentage_suburb)) %>% 
  ungroup()) %>% 
  inner_join(tmp %>% 
               select(official_suburb)) %>% 
  arrange(desc(med_percentage)) 

tmp %>% 
  kable(format = "simple") %>%
  kable_styling( position = "left")

# explore codes for top 5

x <- tmp$official_suburb[1:5]

dta_dir %>% 
  filter(official_suburb %in% x) %>% 
  group_by(official_suburb, code) %>% 
  count() %>% 
  ungroup() %>% 
  ggplot(aes(n, code, fill = official_suburb))+
  geom_col(position = "dodge")

# top 3


select_suburbs <- c("PARKLANDS", "MILNERTON")

```



## 1. Focusing on the Urban Mobility directorate - "What is the median & 80th percentile time to complete each service request across the City?" (each row represent a service request).

```{r}

# exclude data with no completion time, create diff var

dta_dir <- dta_dir %>% 
  filter(!is.na(completion_timestamp)) 

```


```{r}

# summary(dta_dir$time_hours)

# check for outliers in time_hours

# tmp <- dta_dir %>%
#   summarise(q25 = quantile(time_hours, probs = 0.25),
#             q75 = quantile(time_hours, probs = 0.75),
#             iqr = q75 - q25,
#             ol_cutoff = 1.5*iqr + q75)
# 
# dta_dir %>% 
#   group_by(time_hours > tmp$ol_cutoff) %>% 
#   count()
# 
# dta_dir %>% 
#   filter(time_days >= tmp$ol_cutoff) %>% 
#   ggplot(aes(time_hours, official_suburb, 
#              colour = official_suburb))+
#   geom_jitter()+
#   facet_wrap(~code, scales = "free_y")+
#   theme(legend.position = "none")


#  create table with medians, q80 for all suburbs and for all of city 

time_tables_make <- function(dataset = dta_dir, time_cutoff = NULL){
  
  sub_txt <- "ALL COMBINED"
  code_txt <- "All codes combined"
  
  if(is.null(time_cutoff)){
  
  tabledta <- dataset %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
                 mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup())

  return(tabledta)
  
} else if(!is.null(time_cutoff)){
  
  dataset_x <- dataset %>% 
    filter(time_hours < time_cutoff)
  
  tabledta_below <- dataset_x %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset_x %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
              mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup())
  
  dataset_x <- dataset %>% 
    filter(time_hours >= time_cutoff)
  
  tabledta_above <- dataset_x %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
  mutate(official_suburb = sub_txt) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup()) %>% 
  mutate(code = code_txt) %>% 
    bind_rows(dataset_x %>% 
                group_by(code) %>% 
                summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
              mutate(official_suburb = sub_txt)) %>% 
  bind_rows(dataset_x %>% 
  group_by(official_suburb, code) %>% 
  summarise(n = n(),
            med_time_hours = median(time_hours),
            q80_time_hours = quantile(time_hours, probs = 0.8)) %>% 
    ungroup())
  
  return(list(tabledta_below = tabledta_below,
                tabledta_above = tabledta_above))
}
}

time_dta_list <- list()

# for all of city, all codes, all completion time lengths

time_dta_list$all_times <- time_tables_make(dataset = dta_dir, time_cutoff = NULL)

# for all of city, all codes, split by times < or > 24hrs
tmp <- time_tables_make(dataset = dta_dir, time_cutoff = 24)

time_dta_list$below_24 <- tmp$tabledta_below 
time_dta_list$above_eq_24 <- tmp$tabledta_above 

# look at suburbs with n >= 5
# all codes combined

n_cutoff <- 5
sub_txt <- "ALL COMBINED"
code_txt <- "All codes combined"

time_dta_list$all_times %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(format = "simple", caption = "City-wide, all codes combined") %>%
  kable_styling( position = "left")

# filter by < 24 hrs

time_dta_list$below_24 %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(format = "simple", caption = "City-wide, all codes combined, only requests completed in less than 24 hours") %>%
  kable_styling( position = "left")

# > 24 hrs

time_dta_list$above_eq_24 %>% 
  filter(official_suburb == sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  kable(format = "simple", caption = "City-wide, all codes combined, only requests completed in 24 hours or more") %>%
  kable_styling( position = "left")

# split by 24 hours

x <- time_dta_list$below_24 %>% 
  filter(official_suburb == "ALL COMBINED" &
           code == "All codes combined") %>% 
  pull(n)

x <- time_dta_list$all_times %>% 
  filter(official_suburb == "ALL COMBINED" &
           code == "All codes combined") %>% 
  mutate(perc = x/n*100) %>% 
  pull(perc)
  
# x

time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  arrange(desc(med_time_hours)) %>% 
  slice(1:5) %>% 
  kable(format = "simple", caption = "Top 5 suburbs with longest median completion times, all codes combined") %>%
  kable_styling( position = "left")

time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == code_txt &
           n >= n_cutoff) %>% 
  arrange(med_time_hours) %>% 
  slice(1:5) %>% 
  kable(format = "simple", caption = "Top 5 suburbs with shortest median completion times, all codes combined") %>%
  kable_styling(position = "left")



# split by codes
# codes with > 5 requests, per suburb
# show top 5 per code

# get codes for which > 5 requests for some suburbs

n_cutoff <- 5

x <- dta_dir %>% 
  group_by(code, official_suburb) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  filter(n >= n_cutoff) %>% 
  ungroup() %>% 
  distinct(code) %>% 
  pull(code)

sub_txt <- "ALL COMBINED"
time_cutoff <- 24

p1 <- map(x,
    ~time_dta_list$below_24 %>% 
  filter(official_suburb != sub_txt &
           code == .x &
           n >= n_cutoff) %>% 
  select(official_suburb, code) %>% 
    distinct() %>% 
    inner_join(dta_dir %>% 
                 filter(time_hours < time_cutoff))) %>% 
  bind_rows() %>% 
  ggplot(aes(time_hours, official_suburb))+
    ggdist::stat_interval()+
  facet_wrap(~code, scales = "free_y", ncol = 1)


p2 <- map(x,
    ~time_dta_list$above_eq_24 %>% 
  filter(official_suburb != sub_txt &
           code == .x &
           n >= n_cutoff) %>% 
  select(official_suburb, code) %>% 
    distinct() %>% 
    inner_join(dta_dir %>% 
                 filter(time_hours >= time_cutoff))) %>% 
  bind_rows() %>% 
  ggplot(aes(time_hours, official_suburb))+
    ggdist::stat_interval()+
  facet_wrap(~code, scales = "free_y",
             ncol = 1)

ggpubr::ggarrange(p1, p2, ncol = 1, nrow = 2,
                  heights = c(2,1))

tmp <- map(x,
           ~time_dta_list$all_times %>% 
  filter(official_suburb != sub_txt &
           code == .x &
           n >= n_cutoff) %>% 
  arrange(desc(med_time_hours))) 

x <- seq(1,length(tmp), by = 2)

kable(tmp[1:2], format = "simple") %>%
    kable_styling( position = "left")



# per month




# weekends, public holidays?

```



## 2. Focusing on the Urban Mobility directorate - "What is the median & 80th percentile time to complete each service request for the 3 suburbs identified in (1)?" (each row represent a service request).



## 3. "Is there any significant differences in the median and 80th percentile completion times between the City as a whole and the 3 suburbs identified in(1)?".  Please elaborate on the similarities or differences.

```{r}


time_dta_list$all_times %>% 
  filter(official_suburb %in% c(select_suburbs, "ALL COMBINED")) 

# wilcox test
map(select_suburbs,
    ~dta_dir %>% 
  select(official_suburb, time_hours) %>%
  mutate(suburb_bin = case_when(official_suburb %in% 
                                  .x ~ .x,
                                TRUE ~ "ALL COMBINED")) %>% 
  summarise(suburb = .x,
            p_value = wilcox.test(time_hours ~ 
                                    suburb_bin)$p.value))

# prop.test

prop_test_list <- list()

for(i in 1:length(select_suburbs)){
x <- time_dta_list$all_times %>% 
  filter(official_suburb %in% "ALL COMBINED" &
           code == "All codes combined") %>% 
  pull(med_time_hours)

tmp <- dta_dir %>% 
  select(official_suburb, time_hours) %>%
  mutate(med_compare = case_when(time_hours < x ~ "below_coct_median",
                                time_hours >= x ~ "above_or_eq_coct_med")) %>% 
  mutate(suburb_bin = case_when(official_suburb %in% 
                                  select_suburbs[i] ~ select_suburbs[i],
                                TRUE ~ "ALL COMBINED")) %>% 
  group_by(med_compare, suburb_bin) %>% 
  count() %>% 
  pivot_wider(names_from = med_compare, values_from = n) %>% 
  ungroup() %>% 
  select(-suburb_bin) 

prop_test_list[[i]] <- tibble(suburb = select_suburbs[i],
       p_value = prop.test(as.matrix(tmp))$p.value)

}

prop_test_list

```


## 3. Provide a visual mock of a dashboard for the purpose of monitoring progress in applying the insights developed in (1) & (2). It should focus the user on performance pain points. Add a note for each visual element, explaining how it helps fulfill this overall function. Please also provide a brief explanation as to how the data provided would be used to realise what is contained in your mock.


## 4. Identify value-adding insights for the management of Urban Mobility, from the dataset provided, in regard to commuter transport within the City.
 
 
```{r}
# traffic congestion over time
 
 unique(dta_dir$code)
 
 code_txt <- "Conjested Traffic at Intersection"
 
tmp <- dta_dir %>% 
 mutate(across(creation_timestamp, ~as_date(.x))) %>% 
 filter(code == code_txt) %>% 
 group_by(code,creation_timestamp) %>% 
 count() %>% 
 ungroup() 

x <- sort(tmp$n, decreasing = TRUE)
x <- x[6]

tmp %>% 
mutate(day_of_week = wday(creation_timestamp, label=TRUE),
       label = case_when(n > x ~ 
                           paste(day_of_week, creation_timestamp),
                         TRUE ~ "")) %>% 
   
 ggplot(aes(creation_timestamp, n, group = code,
            label = label))+
 geom_line(colour = "grey70")  +
 geom_point()+
   geom_text()

dta_dir %>% 
 mutate(create_date = as_date(creation_timestamp)) %>% 
 filter(code == code_txt) %>% 
 group_by(code,create_date) %>% 
 count() %>% 
 ungroup() %>% 
  filter(n > x) %>% 
  select(-n) %>% 
  inner_join(dta_dir) %>% 
  group_by(create_date,official_suburb) %>% 
  count() %>% 
  ungroup() %>% 
  ggplot(aes(n, reorder(official_suburb,n), fill = as.factor(create_date)))+
  geom_col()

 
 
 # which days of the week have more traffic congestion reports
 
 x <- dta_dir %>% 
   group_by(code) %>% 
   count() %>% 
   arrange(desc(n)) %>% 
   ungroup() %>% 
   slice(1:5) %>% 
   pull(code)
 
 dta_dir %>% 
   filter(code %in% x) %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 group_by(code, day_of_week) %>% 
 count() %>%
   ggplot(aes(day_of_week, n, group = code, colour = code))+
 geom_point()+
 geom_line()
   
 
 dta_dir %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 filter(code == code_txt) %>% 
 group_by(day_of_week) %>% 
 count() %>% 
 ggplot(aes(day_of_week, n))+
 geom_col()
 
 # ?stats
 # odds of having congestion on a wednesday vs other weekdays
 
 
 # suburbs and days of week
 
x <-  dta_dir %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 group_by(day_of_week, official_suburb) %>% 
 count() %>% 
   ungroup() %>% 
   arrange(desc(n)) %>% 
   slice(1:10) %>% 
   pull(n)
 
x <- x[length(x)] 

sz <- 3
 dta_dir %>% 
 mutate(day_of_week = wday(creation_timestamp, label=TRUE)) %>% 
 group_by(day_of_week, official_suburb) %>% 
 count() %>% 
   mutate(label = case_when(n >= x ~ official_suburb,
                          TRUE ~ "")) %>% 
   ggplot(aes(day_of_week, n, label = label))+
   geom_point(alpha = 0.6)+
   geom_text(alpha = 0.5, size = sz, check_overlap = TRUE)
 
```
 
 
 
 
 
 
 
 